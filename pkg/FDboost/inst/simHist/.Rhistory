## compare penalty of %O% effect with l2=0
extract(mod_new, "penalty")[[1]] / extract(mod_new, "lambda")[[1]]
# with penalty of bbs()
extract(bbs(x1, knots = 2, df=5), "penalty")
## look at df and lambda
extract(mod_new, "df")
extract(mod_new, "lambda")
volf <- matrix(fitted(mod_new), nrow = nrow(volcano))
image(volf, main = "fitted")
library(mboost)
library(Matrix)
source('issue19O.R', echo=TRUE)
source('Z:/github/issue19O.R', echo=TRUE)
### kronecker product for matrix-valued responses
data("volcano", package = "datasets")
layout(matrix(1:2, ncol = 2))
## estimate mean of image treating image as matrix
image(volcano, main = "data")
x1 <- 1:nrow(volcano)
x2 <- 1:ncol(volcano)
# create a factor variable
x3 <- gl(2, k=32, length = ncol(volcano))
vol <- as.vector(volcano)
## fit the model using %myO% and df combined with lambda=0
mod_new <- mboost(vol ~ bbs(x1, knots = 2, df=5) %myO% bols(x3, lambda=0),
control = boost_control(nu = 0.25))
## compare penalty of %O% effect with l2=0
extract(mod_new, "penalty")[[1]] / extract(mod_new, "lambda")[[1]]
# with penalty of bbs()
extract(bbs(x1, knots = 2, df=5), "penalty")
## look at df and lambda
extract(mod_new, "df")
extract(mod_new, "lambda")
## look at fitted values
volf <- matrix(fitted(mod_new), nrow = nrow(volcano))
image(volf, main = "fitted")
source('~/.active-rstudio-document', echo=TRUE)
source('Z:/github/issue19O.R', echo=TRUE)
mod_new <- mboost(vol ~ bbs(x1, knots = 2, df=5) %myO% bols(x3, lambda=0),
control = boost_control(nu = 0.25))
df2lambda
?bols
## the old-fashioned way, a waste of space and time
x <- expand.grid(x1, x2)
modx <- mboost(vol ~ bbs(Var2, df = 3, knots = 10) %X%
bbs(Var1, df = 3, knots = 10), data = x,
control = boost_control(nu = 0.25))
modx[250]
modx <- mboost(vol ~ bbs(Var2, df = 3, knots = 10) %X%
bbs(Var1, lambda = 0, knots = 10), data = x,
control = boost_control(nu = 0.25))
modx <- mboost(vol ~ bbs(Var2, df = 3, knots = 10) %X%
bols(Var1, lambda = 0, knots = 10), data = x,
control = boost_control(nu = 0.25))
modx <- mboost(vol ~ bbs(Var2, df = 3, knots = 10) %X%
bols(Var1, lambda = 0), data = x,
control = boost_control(nu = 0.25))
%X%
get(%X%)
get('%X%')
x <- expand.grid(x1, x3)
modx <- mboost(vol ~ bbs(Var2, df = 3, knots = 10) %X%
bols(Var1), data = x,
control = boost_control(nu = 0.25))
modx <- mboost(vol ~ bols(Var2) %X%
bbs(Var1, df = 3, knots = 10), data = x,
control = boost_control(nu = 0.25))
modx <- mboost(vol ~ bols(Var2, intercept = FALSE, lambda=0) %X%
bbs(Var1, df = 3, knots = 10), data = x,
control = boost_control(nu = 0.25))
modx <- mboost(vol ~ bols(Var2, intercept = FALSE, lambda=0) %X%
bbs(Var1, df = 3, knots = 3), data = x,
control = boost_control(nu = 0.25))
extract(modx, "penalty")
modx <- mboost(vol ~ bols(Var2, intercept = TRUE, lambda=0) %X%
bbs(Var1, df = 3, knots = 3), data = x,
control = boost_control(nu = 0.25))
extract(modx, "penalty")
extract(modx, "lambda")
modx <- mboost(vol ~ bols(Var2, intercept = TRUE, lambda=0) %X%
bbs(Var1, df = 2, knots = 3), data = x,
control = boost_control(nu = 0.25))
extract(modx, "penalty")
extract(modx, "lambda")
modx <- mboost(vol ~ bols(Var2, intercept = TRUE, lambda=0) %X%
bbs(Var1, df = 4, knots = 3), data = x,
control = boost_control(nu = 0.25))
extract(modx, "penalty")
extract(modx, "lambda")
modx <- mboost(vol ~ bols(Var2, intercept = TRUE, lambda=0) %X%
bbs(Var1, df = 5, knots = 3), data = x,
control = boost_control(nu = 0.25))
extract(modx, "penalty")
extract(modx, "lambda")
modx <- mboost(vol ~ bols(Var2, intercept = TRUE, df=3) %X%
bbs(Var1, df = 5, knots = 3), data = x,
control = boost_control(nu = 0.25))
extract(modx, "penalty")
extract(modx, "lambda")
modx <- mboost(vol ~ bols(Var2, intercept = TRUE, df=3) %X%
bbs(Var1, df = 4, knots = 3), data = x,
control = boost_control(nu = 0.25))
extract(modx, "penalty")
extract(modx, "lambda")
extract(modx, "df")
modx <- mboost(vol ~ bols(Var2, intercept = TRUE, lambda=0) %X%
bbs(Var1, df = 5, knots = 3), data = x,
control = boost_control(nu = 0.25))
extract(modx, "penalty")
extract(modx, "lambda")
extract(modx, "df")
extract(modx, "lambda")
modx <- mboost(vol ~ bols(Var2, intercept = TRUE, lambda=0) %X%
bbs(Var1, df = 5, knots = 2), data = x,
control = boost_control(nu = 0.25))
extract(modx, "penalty")
extract(modx, "lambda")
extract(modx, "df")
extract(mod_new, "lambda")
extract(modx, "lambda")
## gives the same like
extract(mod_new, "lambda")
Var2
x$Var2
x$dummy1 <- x$Var1
x$dummy1[x$Var1==2] <- 0
x$dummy2 <- x$Var1
x$dummy2[x$Var1==1] <- 0
modd <- mboost(vol ~ bbs(dummy1, df = 4, knots = 3) +
bbs(dummy2, df = 4, knots = 3),
data = x,
control = boost_control(nu = 0.25))
extract(modd, "df")
extract(modd, "lambda")
67*67
?gm
?gam
library(mgcv)
?gam
?s
?gam.vcomp
set.seed(3)
require(mgcv)
## simulate some data, consisting of a smooth truth + random effects
dat <- gamSim(1,n=400,dist="normal",scale=2)
a <- factor(sample(1:10,400,replace=TRUE))
b <- factor(sample(1:7,400,replace=TRUE))
Xa <- model.matrix(~a-1)    ## random main effects
Xb <-  model.matrix(~b-1)
Xab <- model.matrix(~a:b-1) ## random interaction
dat$y <- dat$y + Xa%*%rnorm(10)*.5 +
Xb%*%rnorm(7)*.3 + Xab%*%rnorm(70)*.7
dat$a <- a;dat$b <- b
## Fit the model using "re" terms, and smoother linkage
mod <- gam(y~s(a,bs="re")+s(b,bs="re")+s(a,b,bs="re")+s(x0,id=1)+s(x1,id=1)+
s(x2,k=15)+s(x3),data=dat,method="ML")
gam.vcomp(mod)
plot(mod)
gam.vcomp()
library(gamlss)
data(abdom)
mod<-gamlss(y~pb(x),sigma.fo=~pb(x),family=BCT, data=abdom, method=mixed(1,20))
fitFun <- function(data){
mydata <- data[1:500,]
mod <- gamlss(y~pb(x), sigma.fo=~pb(x), family=BCT, data=mydata)
return(mod)
}
test <- fitFun(data=abdom)
data(abdom)
mod<-gamlss(y~pb(x),sigma.fo=~pb(x),family=BCT, data=abdom, method=mixed(1,20))
fitFun <- function(data){
mydata <- data[1:500,]
myformula <- y~pb(x)
mod <- gamlss(myformula, sigma.fo=~pb(x), family=BCT, data=mydata)
return(mod)
}
test <- fitFun(data=abdom)
fitFun <- function(data){
mydata <- data[1:500,]
myformula1 <- y ~ pb(x)
myformula2 <- ~ pb(x)
mod <- gamlss(myformula, sigma.fo=myformula2, family=BCT, data=mydata)
return(mod)
}
test <- fitFun(data=abdom)
fitFun <- function(data){
mydata <- data[1:500,]
myformula1 <- y ~ pb(x)
myformula2 <- ~ pb(x)
mod <- gamlss(myformula1, sigma.fo=myformula2, family=BCT, data=mydata)
return(mod)
}
test <- fitFun(data=abdom)
fitFun <- function(data, myformula){
mydata <- data[1:500,]
myformula2 <- ~ pb(x)
mod <- gamlss(myformula, sigma.fo=myformula2, family=BCT, data=mydata)
return(mod)
}
myformula1 <- y ~ pb(x)
test <- fitFun(data=abdom, myformula=myformula1)
fitFun <- function(data, myformula){
mydata <- data[1:500,]
myformula2 <- ~ pb(x)
mod <- gamlss(as.formula(myformula), sigma.fo=myformula2, family=BCT, data=mydata)
return(mod)
}
myformula1 <- "y ~ pb(x)"
test <- fitFun(data=abdom, myformula=myformula1)
fitFun <- function(data0, myformula){
mydata <- data0[1:500,]
myformula2 <- ~ pb(x)
mod <- gamlss(as.formula(myformula), sigma.fo=myformula2, family=BCT, data=mydata)
return(mod)
}
myformula1 <- "y ~ pb(x)"
test <- fitFun(data=abdom, myformula=myformula1)
ls()
abdom
test <- fitFun(data0=abdom, myformula=myformula1)
doSim(sub=1, data2=abdom, myformula=myformula1)
doSim <- function(sub, data2, myformula){
mod <- fitFun(data0=data2, myformula=myformula)
return("hello")
}
doSim(sub=1, data2=abdom, myformula=myformula1)
mod <- gamlss(y~pb(x),sigma.fo=~pb(x), family=BCT, data=abdom[1:500,], method=mixed(1,20))
library(mgcv)
?family.gam
?gam.family
?gam
library(mboost)
set.seed(290875)
n <- 100
x1 <- rnorm(n)
x2 <- rnorm(n) + 0.25 * x1
## create a matrix
x12 <- cbind(x1, x2)
dimnames(x12) <- NULL
### more convenient formula interface
temp <- data.frame(x12=I(x12))
mod2 <- mboost(y ~ bols(x12), data= temp)
predict(mod2, newdata=temp )
library(mboost)
set.seed(290875)
n <- 100
x1 <- rnorm(n)
x2 <- rnorm(n)
y <- 1*x1 + 2*x2
## create a matrix
x12 <- cbind(x1, x2)
dimnames(x12) <- NULL
### more convenient formula interface
temp <- data.frame(x12=I(x12))
mod2 <- mboost(y ~ bols(x12), data= temp)
predict(mod2, newdata=temp )
mydata <- data.frame(x12=I(x12), y=y)
str(mydata)
## cannot predict when newdata is supplied
mypred <- predict(mod2, newdata=temp )
mypred <- predict(mod2 )
## cannot predict when newdata is supplied
mypred <- predict(mod2, newdata=temp )
traceback()
debug(predict)
mypred <- predict(mod2, newdata=mydata )
mypred <- predict(mod2, newdata=mydata )
mypred <- predict(mod2, newdata=mydata )
debug(object$predict)
debug(pfun)
debug(bl[[w]]$predict)
mypred <- predict(mod2, newdata=mydata )
str(newdata)
debug(newX)
str(check_newdata(newdata, blg, mf))
str(newdata)
debug(check_newdata)
nm
nm
names(blg)
blg
names(blg)
myblg <- bols(x12)
names(myblg)
myblg$get_names()
myblg1 <- bols(x1)
myblg1$get_names()
bols
debug(bols)
myblg <- bols(x12)
str(mf)
str(mf)
str(list(...))
sapply(cl, function(x) as.character(x))
match.call(expand.dots = FALSE)
as.list(match.call(expand.dots = FALSE))[2][[1]]
library(mboost)
set.seed(290875)
n <- 100
x1 <- rnorm(n)
x1 <- x1 - mean(x1)
x2 <- rnorm(n) + 0.25 * x1
x2 <- x2 - mean(x2)
y <- 3 * x1 + x2
# save x1 and x2 together in a matrix
# x12 <- cbind(x1, x2)
x12 <- matrix(c(x1, x2), ncol=2)
colnames(x12)
###########################
## look at the base-learner
bl1 <- bols(x12)
# gives back the colnames of mf, which are NULL for the matrix
bl1$get_names()
if(FALSE){
# set the colnames
colnames(x12) <- c("x1", "x2")
bl1 <- bols(x12)
bl1$get_names()
### predict does not work either
}
###########################
### set up a dataframe with x12 contained as matrix
temp <- data.frame(y = y, x12 = I(x12))
mod2 <- mboost(y ~ bols(x12), data = temp)
coef(mod2)
## predict() with newdata, try some differnt versions of newdata
## does not work as the dataset does not contain x1 and x2
predict(mod2, newdata=temp )
temp2 <- data.frame(x1 = x1, x2 = x2)
predict(mod2, newdata=temp2 )
temp3 <- data.frame(x1 = I(x12), x2 = I(x12))
predict(mod2, newdata = temp3 )
## use bols(x1, x2)
mydata <- data.frame(y=y, x1=x1, x2=x2)
mod3 <- mboost(y ~ bols(x1, x2, intercept=FALSE), data = mydata)
coef(mod3)
## predic works with newdata
predict(mod3, newdata = mydata )
head( predict(mod3, newdata = mydata ) )
coef(mod3)
coef(mod2)
library(mboost)
### kronecker product for matrix-valued responses
data("volcano", package = "datasets")
layout(matrix(1:2, ncol = 2))
## estimate mean of image treating image as matrix
image(volcano, main = "data")
x1 <- 1:nrow(volcano)
x2 <- 1:ncol(volcano)
vol <- as.vector(volcano)
mod <- mboost(vol ~ bbs(x1, df = 3, knots = 10)%O%
bbs(x2, df = 3, knots = 10),
control = boost_control(nu = 0.25))
## use predict() with newdata
temp <- matrix(predict(mod, newdata=list(x1=x1, x2=x2)), nrow = nrow(volcano))
image(temp, main = "predicted")
## use predict() with newdata that extrapolates the original variables
## does not work as the arument prediciton is not passed in %O%
temp <- matrix(predict(mod, newdata=list(x1=x1, x2=1:62)), nrow = nrow(volcano))
library(mboost)
### kronecker product for matrix-valued responses
data("volcano", package = "datasets")
## estimate mean of image treating image as matrix
x1 <- 1:nrow(volcano)
x2 <- 1:ncol(volcano)
vol <- as.vector(volcano)
mod <- mboost(vol ~ bbs(x1, df = 3, knots = 10)%O%
bbs(x2, df = 3, knots = 10),
control = boost_control(nu = 0.25))
## use predict() with newdata that extrapolates the original variables
## does not work as the arument prediciton is not passed in %O%
temp <- matrix(predict(mod, newdata=list(x1=x1, x2=1:62)), nrow = nrow(volcano))
library(mboost)
### setting with 'p>n' gives warning in rankMatrix
set.seed(290875)
n <- 10
x1 <- rnorm(n)
y <- 2*x1
mod2 <- mboost(y ~ bbs(x1, df = 4))
dim(extract(mod2, "design")[[1]])
# options(warn = 1)
### for comparison: setting with 'p<n' does not give this warning
set.seed(290875)
n <- 30
x1 <- rnorm(n)
y <- 2*x1
mod2 <- mboost(y ~ bbs(x1, df = 4))
dim(extract(mod2, "design")[[1]])
cvrisk(mod2)
set.seed(290875)
n <- 10
x1 <- rnorm(n)
y <- 2*x1
mod2 <- mboost(y ~ bbs(x1, df = 4))
dim(extract(mod2, "design")[[1]])
# options(warn = 1)
cvrisk(mod2)
warnings()
library(mboost)
?glmboost
### sparse high-dimensional example that makes use of the matrix
### interface of glmboost and uses the matrix representation from
### package Matrix
library("Matrix")
n <- 100
p <- 10000
ptrue <- 10
X <- Matrix(0, nrow = n, ncol = p)
X[sample(1:(n * p), floor(n * p / 20))] <- runif(floor(n * p / 20))
beta <- numeric(p)
beta[sample(1:p, ptrue)] <- 10
y <- drop(X %*% beta + rnorm(n, sd = 0.1))
mod <- glmboost(y = y, x = X, center = TRUE) ### mstop needs tuning
coef(mod, which = which(beta > 0))
plot(mod)
temp <- predict(mod, which=1:5)
str(temp)
head(temp)
temp
temp <- predict(mod, which=1:1000)
str(temp)
image(temp)
colMeans(temp)
library(xgboost)
install.packages("xgboost")
library(xgboost)
?xgboost
## checkout developer version of project
# svn checkout svn+ssh://sbrockhaus@r-forge.r-project.org/svnroot/fdboost/
# setwd("~/fdboost9/fdboost/pkg")
setwd("Z:/fdboost9/fdboost/pkg")
# setwd("L:/fdboost9/fdboost/pkg")
library(devtools)
library(roxygen2)
document("FDboost") # updating Rd-files if necessary
# check_doc("FDboost") # check documentation
# load package without packing it -> loads by default all functions!
load_all("FDboost")
setwd("Z:/fdboost9/fdboost/pkg/FDboost/inst/simHist")
library(refund)
library(splines)
library(MASS)
library(Matrix)
# setwd("../")
# path <- getwd()
#
# source(paste0(getwd(),"/Code/boosting4.R"))    # functions for simulations
#
# pathResults <- paste0(path, "/results/")
# pathModels <- paste0(path, "/models/")
source("boosting4.R")
pathResults <- NULL
pathModels <- NULL
getwd()
###################################### M=30
set.seed(18102012)
arginS <- "smooth"
penaltyS <- "ps"
set1 <- makeSettings(
dgpsettings=list(M=c(30),
ni=c(1),
p=c(0.8),
Gy=c(27),
Gx=c(100),
snrEps=c(2),
snrE=c(0),
snrB=c(2),
scenario=c(2),
k=c(0, 1, 2),
type=c("lines"),
balanced=c(TRUE),
nuisance=c(0),  # 10
a=c("pen1coef4", "pen2coef4"),
regularS=c(TRUE),
regularT=c(FALSE),
rep=1:20),
algorithms=list(addNoise=c(FALSE),
centerX=c(TRUE),
penaltyS=c("ps","pss"),
diffPen=c(1,2),
inS=c("smooth"))
)
set1 <- makeSettings(
dgpsettings=list(M=c(30),
ni=c(1),
p=c(0.8),
Gy=c(27),
Gx=c(100),
snrEps=c(2),
snrE=c(0),
snrB=c(2),
scenario=c(2),
k=c(2),
type=c("lines"),
balanced=c(TRUE),
nuisance=c(0),  # 10
a=c("pen1coef4", "pen2coef4"),
regularS=c(TRUE),
regularT=c(FALSE),
rep=1:2),
algorithms=list(addNoise=c(FALSE),
centerX=c(TRUE),
penaltyS=c("ps","pss"),
diffPen=c(1,2),
inS=c("smooth"))
)
length(set1)
usecores <- 5
options(cores=usecores)
# FAMM on set1
pffr1 <- try(doSimPffr(settings=set1, cores=usecores))
pffr1
