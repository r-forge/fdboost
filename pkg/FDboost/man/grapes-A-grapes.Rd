% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/constrainedX.R
\name{\%A\%}
\alias{\%A\%}
\title{Kronecker product of two base-learners with anisotropic penalty}
\usage{
bl1 \%A\% bl2
}
\arguments{
\item{bl1}{base-learner 1, e.g. \code{bbs(x1)}}

\item{bl2}{base-learner 2, e.g. \code{bbs(x2)}}
}
\description{
EXPERIMENTAL!
}
\details{
Ignores weights that are specified in the model-call for the computation of
the anisotropic penalty!

EXPERIMENTAL!

When \code{\%O\%} is called with a specification of \code{df} in both base-learners,
e.g. \code{bbs(x1, df = df1) \%O\% bbs(t, df = df2)}, the global \code{df} for the
Kroneckered base-learner is computed as \code{df = df1 * df2}.
And thus the penalty has only one smoothness parameter lambda resulting in an isotropic penalty,
\deqn{P = lambda * [(P1 o I) + (I o P2)],}
with overall penalty \eqn{P}, Kronecker product \eqn{o},
marginal penalty matrices \eqn{P1, P2} and identity matrices \eqn{I}.
(Currie et al. (2006) introduced the generalized linear array model, which has a design matrix that
is composed of the Kronecker product of two marginal design matrices, which was implemented in mboost
as \code{\%O\%}.
See Brockhaus et al. (2015) for the application of array models to functional data.)

In contrast, a Kronecker product with anisotropic penalty is obtained by \code{\%A\%},
which allows for a different amount of smoothness in the two directions.
For example \code{bbs(x1, df = df1) \%A\% bbs(t, df = df2)} results in computing two
different values for lambda for the two marginal design matrices and a global value of
lambda to adjust for the global \code{df}, i.e.
\deqn{P = lambda * [(lambda1 * P1 o I) +  (I o lambda2 * P2)],}
with Kronecker product \eqn{o},
where \eqn{lambda1} is computed individually for \eqn{df1} and \eqn{P1},
\eqn{lambda2} is computed individually for \eqn{df2}  and \eqn{P2},
and \eqn{lambda} is computed such that the global \eqn{df} hold \eqn{df = df1 * df2}.
For the computation of \eqn{lambda1} and \eqn{lambda2} weights specified in the model
call are not used, this implies that \eqn{lambda1} and \eqn{lambda2} are equal over
folds of \code{cvrisk}. The computation of the global \eqn{lambda} considers the
specified \code{weights}, such the global \eqn{df} are correct.

If the \code{formula} in \code{FDboost} contains base-learners connected by
\code{\%O\%} or \code{\%A\%},
those effects are not expanded with \code{timeformula}, allowing for model specifications
with different effects in time-direction.
}
\examples{
######## Example for anisotropic penalty
data("viscosity", package = "FDboost")
## set time-interval that should be modeled
interval <- "101"

## model time until "interval" and take log() of viscosity
end <- which(viscosity$timeAll == as.numeric(interval))
viscosity$vis <- log(viscosity$visAll[,1:end])
viscosity$time <- viscosity$timeAll[1:end]
# with(viscosity, funplot(time, vis, pch = 16, cex = 0.2))

## isotropic penalty, as timeformula is kroneckered to each effect using \%O\%...
mod1 <- FDboost(vis ~ 1 +
                bolsc(T_C, df=1) +
                bolsc(T_A, df=1) +
                bols(T_C, df=1) \%Xc\% bols(T_A, df=1),
                timeformula = ~ bbs(time, df=3),
                numInt = "equal", family = QuantReg(),
                offset = NULL, offset_control = o_control(k_min = 9),
                data = viscosity, control=boost_control(mstop = 200, nu = 0.4))
## cf. the formula that is passed to mboost
mod1$formulaMboost

## anisotropic effects using \%A\%
mod1a <- FDboost(vis ~ 1 +
                bolsc(T_C, df=1) \%A\% bbs(time, df=3) +
                bolsc(T_A, df=1) \%A\% bbs(time, df=3) +
                bols(T_C, df=1) \%Xc\% bols(T_A, df=1) \%A\% bbs(time, df=3),
                timeformula = ~ bbs(time, df=3),
                numInt = "equal", family = QuantReg(),
                offset = NULL, offset_control = o_control(k_min = 9),
                data = viscosity, control=boost_control(mstop = 200, nu = 0.4))

## optimize mstop for mod1 and mod1a
## ...

## compare estimated coefficients
\dontrun{
par(mfrow=c(4, 2))
plot(mod1, which = 1)
plot(mod1a, which = 1)
plot(mod1, which = 2)
plot(mod1a, which = 2)
plot(mod1, which = 3)
plot(mod1a, which = 3)
funplot(mod1$yind, predict(mod1, which=4))
funplot(mod1$yind, predict(mod1a, which=4))
}
}
\references{
Brockhaus, S., Scheipl, F., Hothorn, T. and Greven, S. (2015):
The functional linear array model. Statistical Modelling, 15(3), 279-300.

Currie, I.D., Durban, M. and Eilers P.H.C. (2006):
Generalized linear array models with applications to multidimensional smoothing.
Journal of the Royal Statistical Society, Series B-Statistical Methodology, 68(2), 259-280.
}

